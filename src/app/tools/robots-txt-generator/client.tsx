"use client"

import { useState, useEffect, useCallback } from "react"
import { Textarea } from "@/components/ui/textarea"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card"
import ToolPageLayout from "@/components/layout/tool-page-layout"
import { ToolStructuredData } from "@/components/seo/tool-seo"
import {
  FileText,
  Copy,
  Plus,
  Minus,
  Download,
  CheckCircle,
  Bot,
  Shield,
  Link as LinkIcon
} from "lucide-react"

interface RobotsRule {
  userAgent: string
  allow: string[]
  disallow: string[]
  crawlDelay?: number
}

interface SitemapEntry {
  url: string
}

export default function RobotsTxtGeneratorClient() {
  const [rules, setRules] = useState<RobotsRule[]>([
    {
      userAgent: "*",
      allow: [],
      disallow: ["/admin/", "/private/"],
      crawlDelay: undefined
    }
  ])

  const [sitemaps, setSitemaps] = useState<SitemapEntry[]>([
    { url: "https://example.com/sitemap.xml" }
  ])

  const [generatedRobotsTxt, setGeneratedRobotsTxt] = useState("")
  const [copied, setCopied] = useState(false)

  const commonUserAgents = [
    "*",
    "Googlebot",
    "Bingbot",
    "Slurp",
    "DuckDuckBot",
    "Baiduspider",
    "YandexBot",
    "facebookexternalhit",
    "Twitterbot",
    "LinkedInBot",
    "WhatsApp"
  ]

  const commonPaths = [
    "/admin/",
    "/private/",
    "/wp-admin/",
    "/wp-login.php",
    "/cgi-bin/",
    "/tmp/",
    "/temp/",
    "/cache/",
    "/logs/",
    "/backup/",
    "/.git/",
    "/.env",
    "/api/private/",
    "/dashboard/",
    "/settings/"
  ]

  const generateRobotsTxt = useCallback(() => {
    let content = "# Robots.txt generated by Tools Hub\n"
    content += "# https://toolshub.com/tools/robots-txt-generator\n\n"

    // Add rules for each user agent
    rules.forEach((rule, index) => {
      if (index > 0) content += "\n"
      content += `User-agent: ${rule.userAgent}\n`

      // Add disallow rules
      rule.disallow.forEach(path => {
        if (path.trim()) {
          content += `Disallow: ${path.trim()}\n`
        }
      })

      // Add allow rules
      rule.allow.forEach(path => {
        if (path.trim()) {
          content += `Allow: ${path.trim()}\n`
        }
      })

      // Add crawl delay if set
      if (rule.crawlDelay && rule.crawlDelay > 0) {
        content += `Crawl-delay: ${rule.crawlDelay}\n`
      }
    })

    // Add sitemaps
    if (sitemaps.length > 0) {
      content += "\n"
      sitemaps.forEach(sitemap => {
        if (sitemap.url.trim()) {
          content += `Sitemap: ${sitemap.url.trim()}\n`
        }
      })
    }

    setGeneratedRobotsTxt(content)
  }, [rules, sitemaps])

  useEffect(() => {
    generateRobotsTxt()
  }, [generateRobotsTxt])

  const addRule = () => {
    setRules([...rules, {
      userAgent: "Googlebot",
      allow: [],
      disallow: [],
      crawlDelay: undefined
    }])
  }

  const removeRule = (index: number) => {
    if (rules.length > 1) {
      setRules(rules.filter((_, i) => i !== index))
    }
  }

  const updateRule = (index: number, field: keyof RobotsRule, value: string | string[] | number | undefined) => {
    const newRules = [...rules]
    newRules[index] = { ...newRules[index], [field]: value }
    setRules(newRules)
  }

  const addPath = (ruleIndex: number, type: 'allow' | 'disallow', path: string) => {
    const newRules = [...rules]
    if (type === 'allow') {
      newRules[ruleIndex].allow = [...newRules[ruleIndex].allow, path]
    } else {
      newRules[ruleIndex].disallow = [...newRules[ruleIndex].disallow, path]
    }
    setRules(newRules)
  }

  const removePath = (ruleIndex: number, type: 'allow' | 'disallow', pathIndex: number) => {
    const newRules = [...rules]
    if (type === 'allow') {
      newRules[ruleIndex].allow = newRules[ruleIndex].allow.filter((_, i) => i !== pathIndex)
    } else {
      newRules[ruleIndex].disallow = newRules[ruleIndex].disallow.filter((_, i) => i !== pathIndex)
    }
    setRules(newRules)
  }

  const addSitemap = () => {
    setSitemaps([...sitemaps, { url: "" }])
  }

  const removeSitemap = (index: number) => {
    setSitemaps(sitemaps.filter((_, i) => i !== index))
  }

  const updateSitemap = (index: number, url: string) => {
    const newSitemaps = [...sitemaps]
    newSitemaps[index] = { url }
    setSitemaps(newSitemaps)
  }

  const handleCopy = async () => {
    try {
      await navigator.clipboard.writeText(generatedRobotsTxt)
      setCopied(true)
      setTimeout(() => setCopied(false), 2000)
    } catch (err) {
      console.error("Failed to copy text:", err)
    }
  }

  const handleDownload = () => {
    const blob = new Blob([generatedRobotsTxt], { type: 'text/plain' })
    const url = URL.createObjectURL(blob)
    const a = document.createElement('a')
    a.href = url
    a.download = 'robots.txt'
    document.body.appendChild(a)
    a.click()
    document.body.removeChild(a)
    URL.revokeObjectURL(url)
  }

  const features = [
    "Generate robots.txt files with multiple user agents",
    "Add allow and disallow rules for precise control",
    "Set crawl delays for different bots",
    "Include multiple sitemap URLs",
    "Real-time preview of generated robots.txt",
    "Download robots.txt file directly",
    "Copy to clipboard functionality",
    "Common paths and user agents suggestions"
  ]

  const useCases = [
    "SEO optimization for websites",
    "Preventing search engines from indexing private content",
    "Controlling crawler behavior on development sites",
    "Setting appropriate crawl rates for server resources",
    "Managing access for different search engine bots",
    "Including sitemaps for better indexing"
  ]

  const tips = [
    "Use '*' as user-agent for all crawlers",
    "Start with restrictive rules and add allowances as needed",
    "Include your XML sitemap URL for better crawling",
    "Test your robots.txt with Google's robots.txt tester",
    "Remember that robots.txt is a suggestion, not a guarantee",
    "Use crawl-delay to prevent overloading your server"
  ]

  const relatedTools = [
    {
      name: "Sitemap Generator",
      href: "/tools/sitemap-generator",
      icon: FileText,
      description: "Generate XML sitemaps"
    },
    {
      name: "Meta Tag Preview Tool",
      href: "/tools/meta-tag-preview",
      icon: Shield,
      description: "Preview meta tags"
    },
    {
      name: "URL Encoder",
      href: "/tools/url-encoder",
      icon: LinkIcon,
      description: "Encode URLs safely"
    }
  ]

  const faqs = [
    {
      question: "What is a robots.txt file?",
      answer: "A robots.txt file tells search engine crawlers which pages or files they can or cannot access on your site. It's placed in the root directory of your website."
    },
    {
      question: "Do all crawlers respect robots.txt?",
      answer: "Most legitimate search engines respect robots.txt, but it's not a security measure. Malicious bots or scrapers may ignore it. Use proper authentication for sensitive content."
    },
    {
      question: "What's the difference between Allow and Disallow?",
      answer: "Disallow tells crawlers not to access certain paths. Allow can override Disallow rules for specific sub-paths within a disallowed directory."
    },
    {
      question: "How do I test my robots.txt file?",
      answer: "You can use tools like Google's Search Console robots.txt tester, or various online robots.txt validators to check your file."
    }
  ]

  return (
    <>
      <ToolStructuredData
        toolName="Robots.txt Generator"
        toolDescription="Generate robots.txt files for your website with customizable rules for search engine crawlers. Control which pages bots can access and set crawl delays."
        category="Developer Tools"
        toolPath="/tools/robots-txt-generator"
      />

      <ToolPageLayout
        toolName="Robots.txt Generator"
        toolDescription="Generate robots.txt files for your website with customizable rules for search engine crawlers. Control which pages bots can access and set crawl delays."
        toolIcon={Bot}
        category="SEO Tools"
        categoryHref="/categories/seo"
        features={features}
        useCases={useCases}
        relatedTools={relatedTools}
        tips={tips}
        faqs={faqs}
      >
        <div className="space-y-6">
          {/* Rules Configuration */}
          <Card>
            <CardHeader>
              <CardTitle className="flex items-center gap-2">
                <Shield className="h-5 w-5 text-primary" />
                Crawler Rules
              </CardTitle>
            </CardHeader>
            <CardContent className="space-y-4">
              {rules.map((rule, ruleIndex) => (
                <div key={ruleIndex} className="border border-gray-200 rounded-lg p-4 space-y-4">
                  <div className="flex items-center justify-between">
                    <h3 className="font-semibold text-gray-900">Rule #{ruleIndex + 1}</h3>
                    {rules.length > 1 && (
                      <Button
                        variant="outline"
                        size="sm"
                        onClick={() => removeRule(ruleIndex)}
                        className="text-red-600 hover:text-red-700"
                      >
                        <Minus className="h-4 w-4" />
                      </Button>
                    )}
                  </div>

                  {/* User Agent */}
                  <div>
                    <label className="block text-sm font-medium text-gray-700 mb-2">User Agent</label>
                    <div className="grid grid-cols-2 md:grid-cols-3 gap-2">
                      {commonUserAgents.map(agent => (
                        <Button
                          key={agent}
                          variant={rule.userAgent === agent ? "default" : "outline"}
                          size="sm"
                          onClick={() => updateRule(ruleIndex, 'userAgent', agent)}
                          className="text-xs"
                        >
                          {agent}
                        </Button>
                      ))}
                    </div>
                  </div>

                  {/* Crawl Delay */}
                  <div>
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                      Crawl Delay (seconds) - Optional
                    </label>
                    <Input
                      type="number"
                      min="0"
                      step="0.1"
                      placeholder="e.g., 1"
                      value={rule.crawlDelay || ""}
                      onChange={(e) => updateRule(ruleIndex, 'crawlDelay', e.target.value ? parseFloat(e.target.value) : undefined)}
                    />
                  </div>

                  {/* Disallow Paths */}
                  <div>
                    <label className="block text-sm font-medium text-gray-700 mb-2">Disallow Paths</label>
                    <div className="space-y-2">
                      {rule.disallow.map((path, pathIndex) => (
                        <div key={pathIndex} className="flex gap-2">
                          <Input
                            value={path}
                            onChange={(e) => {
                              const newDisallow = [...rule.disallow]
                              newDisallow[pathIndex] = e.target.value
                              updateRule(ruleIndex, 'disallow', newDisallow)
                            }}
                            placeholder="/private/"
                          />
                          <Button
                            variant="outline"
                            size="sm"
                            onClick={() => removePath(ruleIndex, 'disallow', pathIndex)}
                          >
                            <Minus className="h-4 w-4" />
                          </Button>
                        </div>
                      ))}
                      <div className="flex gap-2">
                        <div className="flex-1 grid grid-cols-2 md:grid-cols-3 gap-1">
                          {commonPaths.slice(0, 6).map(path => (
                            <Button
                              key={path}
                              variant="outline"
                              size="sm"
                              onClick={() => addPath(ruleIndex, 'disallow', path)}
                              className="text-xs truncate"
                            >
                              {path}
                            </Button>
                          ))}
                        </div>
                        <Button
                          variant="outline"
                          size="sm"
                          onClick={() => addPath(ruleIndex, 'disallow', '')}
                        >
                          <Plus className="h-4 w-4" />
                        </Button>
                      </div>
                    </div>
                  </div>

                  {/* Allow Paths */}
                  <div>
                    <label className="block text-sm font-medium text-gray-700 mb-2">Allow Paths (Optional)</label>
                    <div className="space-y-2">
                      {rule.allow.map((path, pathIndex) => (
                        <div key={pathIndex} className="flex gap-2">
                          <Input
                            value={path}
                            onChange={(e) => {
                              const newAllow = [...rule.allow]
                              newAllow[pathIndex] = e.target.value
                              updateRule(ruleIndex, 'allow', newAllow)
                            }}
                            placeholder="/public/"
                          />
                          <Button
                            variant="outline"
                            size="sm"
                            onClick={() => removePath(ruleIndex, 'allow', pathIndex)}
                          >
                            <Minus className="h-4 w-4" />
                          </Button>
                        </div>
                      ))}
                      <Button
                        variant="outline"
                        size="sm"
                        onClick={() => addPath(ruleIndex, 'allow', '')}
                      >
                        <Plus className="h-4 w-4 mr-2" />
                        Add Allow Path
                      </Button>
                    </div>
                  </div>
                </div>
              ))}

              <Button onClick={addRule} variant="outline" className="w-full">
                <Plus className="h-4 w-4 mr-2" />
                Add Another Rule
              </Button>
            </CardContent>
          </Card>

          {/* Sitemaps */}
          <Card>
            <CardHeader>
              <CardTitle className="flex items-center gap-2">
                <LinkIcon className="h-5 w-5 text-primary" />
                Sitemap URLs
              </CardTitle>
            </CardHeader>
            <CardContent className="space-y-4">
              {sitemaps.map((sitemap, index) => (
                <div key={index} className="flex gap-2">
                  <Input
                    value={sitemap.url}
                    onChange={(e) => updateSitemap(index, e.target.value)}
                    placeholder="https://example.com/sitemap.xml"
                    className="flex-1"
                  />
                  <Button
                    variant="outline"
                    size="sm"
                    onClick={() => removeSitemap(index)}
                    disabled={sitemaps.length === 1}
                  >
                    <Minus className="h-4 w-4" />
                  </Button>
                </div>
              ))}
              <Button onClick={addSitemap} variant="outline" className="w-full">
                <Plus className="h-4 w-4 mr-2" />
                Add Another Sitemap
              </Button>
            </CardContent>
          </Card>

          {/* Generated robots.txt */}
          <Card>
            <CardHeader>
              <div className="flex items-center justify-between">
                <CardTitle className="flex items-center gap-2">
                  <FileText className="h-5 w-5 text-primary" />
                  Generated robots.txt
                </CardTitle>
                <div className="flex gap-2">
                  <Button variant="outline" size="sm" onClick={handleCopy}>
                    {copied ? <CheckCircle className="h-4 w-4 mr-2" /> : <Copy className="h-4 w-4 mr-2" />}
                    {copied ? 'Copied!' : 'Copy'}
                  </Button>
                  <Button onClick={handleDownload}>
                    <Download className="h-4 w-4 mr-2" />
                    Download
                  </Button>
                </div>
              </div>
            </CardHeader>
            <CardContent>
              <Textarea
                value={generatedRobotsTxt}
                readOnly
                className="min-h-[300px] font-mono text-sm"
                placeholder="Your generated robots.txt will appear here..."
              />
            </CardContent>
          </Card>
        </div>
      </ToolPageLayout>
    </>
  )
}